{
  "model_name": "spaf_llama",
  "base_model_path": "path/to/base/llama/model",
  
  "spaf_settings": {
    "enable_spaf": true,
    "cutoff_layer": null,
    "adapter_dim_ratio": 0.25,
    "alignment_head": {
      "num_layers": 2,
      "hidden_dim_ratio": 2.0,
      "hidden_act": "silu"
    }
  },
  
  "training": {
    "learning_rate": 1e-4,
    "weight_decay": 0.01,
    "batch_size": 8,
    "num_epochs": 3,
    "max_seq_length": 512,
    "gradient_accumulation_steps": 1,
    "warmup_steps": 100,
    "logging_steps": 100,
    "save_steps": 1000,
    "eval_steps": 500,
    
    "loss_weights": {
      "alignment": 1.0,
      "adapter_base": 1.0
    },
    "alignment_loss_type": "mse",
    
    "optimizer": "adamw",
    "scheduler": "linear",
    "fp16": true,
    "deepspeed": false
  },
  
  "inference": {
    "num_draft_tokens": 5,
    "serial_parallel_transition": 2,
    "temperature": 0.0,
    "top_p": 0.9,
    "top_k": 50,
    "max_new_tokens": 512,
    "use_cache": true
  },
  
  "data": {
    "train_file": "path/to/train/data",
    "eval_file": "path/to/eval/data",
    "data_format": "json",
    "preprocessing": {
      "add_eos_token": true,
      "truncation": true,
      "padding": "max_length"
    }
  },
  
  "output": {
    "output_dir": "./spaf_checkpoints",
    "save_total_limit": 3,
    "save_strategy": "steps",
    "load_best_model_at_end": true
  },
  
  "notes": {
    "cutoff_layer": "Set to null for auto (num_layers // 2). For 7B models, typically 16; for 13B models, typically 20; for 70B models, typically 40.",
    "adapter_dim_ratio": "Ratio of adapter intermediate dim to hidden size. 0.25 means adapter has 1/4 the parameters of a full layer.",
    "serial_parallel_transition": "Number of serial drafting steps before switching to parallel. Higher values may improve quality but reduce parallelism.",
    "num_draft_tokens": "Number of draft tokens to generate per iteration. More tokens = higher speedup potential but more risk of rejection.",
    "alignment_loss_type": "Choose 'mse' for mean squared error or 'cosine' for cosine similarity loss."
  }
}
