# Hybrid-AgileDrafter

## ğŸ“‹ æ¦‚è¿°

Hybrid-AgileDrafter æ˜¯ Gumiho çš„é‡æ„ç‰ˆæœ¬ï¼Œå°†é™æ€ã€åˆ†ç¦»å¼è‰ç¨¿å¤´æ¶æ„é‡æ„ä¸ºç”±**å¯å¾®é—¨æ§ç½‘ç»œé©±åŠ¨çš„åŠ¨æ€ã€å¼‚æ„åºåˆ—æ¨¡å‹**ã€‚

### æ ¸å¿ƒç‰¹æ€§

1. **åŠ¨æ€å—é€‰æ‹©**ï¼šä½¿ç”¨é—¨æ§ç½‘ç»œæ ¹æ® LLM éšè—çŠ¶æ€åŠ¨æ€é€‰æ‹©æœ€ä½³çš„å¤„ç†å—
2. **å¼‚æ„æ¶æ„**ï¼šç»„åˆè½»é‡çº§ MLP å—å’Œå¼ºå¤§çš„ Transformer å—
3. **æˆæœ¬æ„ŸçŸ¥è®­ç»ƒ**ï¼šé€šè¿‡æˆæœ¬é¢„æœŸæŸå¤±å¹³è¡¡å‡†ç¡®ç‡å’Œè®¡ç®—æ•ˆç‡
4. **å¯å¾®ä¼˜åŒ–**ï¼šä½¿ç”¨ Gumbel-Softmax å®ç°ç«¯åˆ°ç«¯è®­ç»ƒ

## ğŸ—ï¸ æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           LLM Hidden States                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Gating Network â”‚ â† åŸºäºéšè—çŠ¶æ€é€‰æ‹©å—
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ Gumbel-Softmax
                 â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Hybrid Block Seq     â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚  MLP Block 1     â”‚  â”‚ â† è½»é‡çº§ï¼Œæˆæœ¬ä½
    â”‚  â”‚  MLP Block 2     â”‚  â”‚
    â”‚  â”‚  ...             â”‚  â”‚
    â”‚  â”‚  Transformer 1   â”‚  â”‚ â† å¼ºå¤§ï¼Œæˆæœ¬é«˜
    â”‚  â”‚  Transformer 2   â”‚  â”‚
    â”‚  â”‚  ...             â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Weighted Fusionâ”‚ â† åŠ æƒç»„åˆå„å—è¾“å‡º
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
       Final Logits
```

## ğŸ“ æ–‡ä»¶ç»“æ„

```
dynaspec/
â”œâ”€â”€ README.md                      # æœ¬æ–‡æ¡£
â”œâ”€â”€ config.json                    # æ¨¡å‹é…ç½®æ–‡ä»¶
â”œâ”€â”€ train_config.json              # è®­ç»ƒé…ç½®æ–‡ä»¶ï¼ˆç”¨äº DeepSpeedï¼‰
â”œâ”€â”€ ds_config_hybrid.json          # DeepSpeed é…ç½®æ–‡ä»¶
â”œâ”€â”€ gating_network.py              # é—¨æ§ç½‘ç»œå®ç°
â”œâ”€â”€ hybrid_agile_drafter.py        # æ ¸å¿ƒè‰ç¨¿æ¨¡å‹
â”œâ”€â”€ hybrid_model.py                # å®Œæ•´æ¨¡å‹åŒ…è£…å™¨
â”œâ”€â”€ loss.py                        # æŸå¤±å‡½æ•°ï¼ˆæ¨¡ä»¿æŸå¤± + æˆæœ¬æŸå¤±ï¼‰
â”œâ”€â”€ train_hybrid.py                # è®­ç»ƒè„šæœ¬ï¼ˆAccelerateï¼‰
â”œâ”€â”€ train_hybrid_deepspeed.py      # è®­ç»ƒè„šæœ¬ï¼ˆDeepSpeedï¼‰
â”œâ”€â”€ train_deepspeed.sh             # DeepSpeed å¯åŠ¨è„šæœ¬
â”œâ”€â”€ test_basic.py                  # åŸºç¡€æµ‹è¯•è„šæœ¬
â””â”€â”€ __init__.py                    # åŒ…åˆå§‹åŒ–æ–‡ä»¶
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
# Gumiho çš„æ‰€æœ‰ä¾èµ–å·²ç»åŒ…å«æ‰€éœ€çš„åº“
pip install -r requirements.txt
```

### 2. å‡†å¤‡æ•°æ®

ä½¿ç”¨ Gumiho çš„æ•°æ®ç”Ÿæˆè„šæœ¬ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼š

```bash
# ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼ˆä½¿ç”¨ Gumiho çš„æ–¹æ³•ï¼‰
python -m gumiho.ge_data.ge_data_all_llama3 --basepath /path/to/llama3 --output /path/to/output
```

### 3. è®­ç»ƒæ¨¡å‹

#### æ–¹æ³• 1: å• GPU / å°è§„æ¨¡è®­ç»ƒï¼ˆä½¿ç”¨ Accelerateï¼‰

```bash
python dynaspec/train_hybrid.py \
    --basepath /path/to/llama-3-8b \
    --configpath dynaspec/config.json \
    --tmpdir /path/to/training_data \
    --cpdir ./checkpoints/hybrid_agile \
    --bs 4 \
    --lr 3e-5 \
    --num_epochs 20 \
    --cost_lambda 0.01
```

#### æ–¹æ³• 2: å¤š GPU / å¤§è§„æ¨¡è®­ç»ƒï¼ˆä½¿ç”¨ DeepSpeedï¼Œæ¨èï¼‰

1. **é…ç½®è®­ç»ƒå‚æ•°**

ç¼–è¾‘ `dynaspec/train_config.json`:

```json
{
  "training": {
    "num_epochs": 20,
    "start_epoch": 0,
    "save_interval": 5,
    "max_len": 2048
  },
  "model": {
    "num_mlp_blocks": 2,
    "num_transformer_blocks": 3,
    "gumbel_temperature": 1.0
  },
  "loss_weights": {
    "cost_lambda": 0.01,
    "mlp_cost": 1.0,
    "transformer_cost": 5.0
  },
  "paths": {
    "basepath": "/path/to/llama-3-8b",
    "ckpt_dir": "./checkpoints/hybrid_agile_ds"
  },
  "data": {
    "data_dir": "./train_data"
  }
}
```

2. **å¯åŠ¨è®­ç»ƒ**

```bash
# å•å‘½ä»¤å¯åŠ¨
bash dynaspec/train_deepspeed.sh

# æˆ–æ‰‹åŠ¨æŒ‡å®šå‚æ•°
deepspeed --num_gpus=4 \
    dynaspec/train_hybrid_deepspeed.py \
    --config_path dynaspec/train_config.json \
    --deepspeed_config dynaspec/ds_config_hybrid.json
```

3. **ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ**

```bash
deepspeed --num_gpus=4 \
    dynaspec/train_hybrid_deepspeed.py \
    --config_path dynaspec/train_config.json \
    --deepspeed_config dynaspec/ds_config_hybrid.json \
    --existing_model_path ./checkpoints/hybrid_agile_ds/epoch_10/pytorch_model.bin
```

### 4. ä¸»è¦è¶…å‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ | å»ºè®®èŒƒå›´ |
|------|------|--------|---------|
| `num_mlp_blocks` | MLP å—æ•°é‡ | 2 | 1-5 |
| `num_transformer_blocks` | Transformer å—æ•°é‡ | 3 | 1-5 |
| `cost_lambda` | æˆæœ¬æŸå¤±æƒé‡ | 0.01 | 0.001-0.1 |
| `mlp_cost` | MLP å—æˆæœ¬ | 1.0 | å›ºå®šä¸º 1.0 |
| `transformer_cost` | Transformer å—æˆæœ¬ | 5.0 | 3.0-10.0 |
| `gumbel_temperature` | Gumbel-Softmax æ¸©åº¦ | 1.0 | 0.5-2.0 |

## ğŸ’¡ æ ¸å¿ƒç»„ä»¶

### 1. GatingNetwork (é—¨æ§ç½‘ç»œ)

æ ¹æ® LLM éšè—çŠ¶æ€é€‰æ‹©æœ€ä½³å—ï¼š

```python
from dynaspec.gating_network import GatingNetwork

gating = GatingNetwork(input_dim=4096, num_choices=5)
logits = gating(llm_hidden_state)  # [batch_size, num_choices]
```

### 2. HybridAgileDrafter (è‰ç¨¿æ¨¡å‹)

åŠ¨æ€å¼‚æ„åºåˆ—æ¨¡å‹ï¼š

```python
from dynaspec.hybrid_agile_drafter import HybridAgileDrafter

drafter = HybridAgileDrafter(config)
final_logits, gating_probs = drafter(
    inputs=input_embeds,
    llm_hidden_state=hidden_states
)
```

### 3. æŸå¤±å‡½æ•°

ç»„åˆæ¨¡ä»¿æŸå¤±å’Œæˆæœ¬æŸå¤±ï¼š

```python
from dynaspec.loss import compute_hybrid_loss

loss, loss_dict = compute_hybrid_loss(
    draft_logits=draft_logits,
    target_labels=target_ids,
    gating_probs=gating_probs,
    num_mlp_blocks=2,
    num_transformer_blocks=3,
    cost_lambda=0.01
)
```

## ğŸ“Š è®­ç»ƒç›‘æ§

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šè®°å½•ä»¥ä¸‹æŒ‡æ ‡åˆ° WandBï¼š

### æŸå¤±æŒ‡æ ‡
- `train/loss`: æ€»æŸå¤±
- `train/draft_loss`: æ¨¡ä»¿æŸå¤±ï¼ˆäº¤å‰ç†µï¼‰
- `train/expected_cost`: é¢„æœŸè®¡ç®—æˆæœ¬
- `train/cost_loss`: æˆæœ¬æŸå¤±é¡¹

### å‡†ç¡®ç‡æŒ‡æ ‡
- `train/top1_acc`: Top-1 å‡†ç¡®ç‡
- `train/top3_acc`: Top-3 å‡†ç¡®ç‡
- `train/top5_acc`: Top-5 å‡†ç¡®ç‡

### é—¨æ§ç»Ÿè®¡
- `train/gating/mlp_0_prob`: MLP å— 0 è¢«é€‰æ‹©çš„æ¦‚ç‡
- `train/gating/transformer_0_prob`: Transformer å— 0 è¢«é€‰æ‹©çš„æ¦‚ç‡
- `train/gating/mlp_total_prob`: æ‰€æœ‰ MLP å—æ€»æ¦‚ç‡
- `train/gating/transformer_total_prob`: æ‰€æœ‰ Transformer å—æ€»æ¦‚ç‡

## ğŸ”§ é…ç½®è¯´æ˜

### config.json å‚æ•°è¯¦è§£

```json
{
  "num_mlp_blocks": 2,              // MLP å—æ•°é‡ï¼ˆè½»é‡çº§ï¼‰
  "num_transformer_blocks": 3,       // Transformer å—æ•°é‡ï¼ˆé‡é‡çº§ï¼‰
  "gumbel_temperature": 1.0,         // æ¸©åº¦å‚æ•°ï¼Œè¶Šä½è¶Šç¦»æ•£
  "cost_lambda": 0.01,               // æˆæœ¬æŸå¤±æƒé‡ï¼Œè¶Šå¤§è¶Šæ³¨é‡æ•ˆç‡
  "mlp_cost": 1.0,                   // MLP å—ç›¸å¯¹æˆæœ¬
  "transformer_cost": 5.0            // Transformer å—ç›¸å¯¹æˆæœ¬
}
```

### æˆæœ¬æƒè¡¡

- **`cost_lambda` è¾ƒå° (0.001-0.01)**ï¼šæ¨¡å‹æ›´å…³æ³¨å‡†ç¡®ç‡ï¼Œå¯èƒ½æ›´å¤šé€‰æ‹© Transformer å—
- **`cost_lambda` è¾ƒå¤§ (0.05-0.1)**ï¼šæ¨¡å‹æ›´å…³æ³¨æ•ˆç‡ï¼Œå€¾å‘é€‰æ‹© MLP å—
- **å»ºè®®**ï¼šä» 0.01 å¼€å§‹ï¼Œæ ¹æ®é—¨æ§ç»Ÿè®¡è°ƒæ•´

## ğŸ¯ é¢„æœŸæ•ˆæœ

æˆåŠŸè®­ç»ƒåï¼Œæ¨¡å‹åº”è¯¥å±•ç°ä»¥ä¸‹è¡Œä¸ºï¼š

1. **è‡ªé€‚åº”é€‰æ‹©**ï¼š
   - ç®€å•ä¸Šä¸‹æ–‡ â†’ æ›´å¤šä½¿ç”¨ MLP å—
   - å¤æ‚ä¸Šä¸‹æ–‡ â†’ æ›´å¤šä½¿ç”¨ Transformer å—

2. **æ•ˆç‡æå‡**ï¼š
   - ç›¸æ¯”çº¯ Transformerï¼šè®¡ç®—æˆæœ¬é™ä½ 30-50%
   - ç›¸æ¯”çº¯ MLPï¼šå‡†ç¡®ç‡æå‡ 10-20%

3. **é—¨æ§ç»Ÿè®¡**ï¼ˆç†æƒ³æƒ…å†µï¼‰ï¼š
   - MLP å—æ€»æ¦‚ç‡ï¼š40-60%
   - Transformer å—æ€»æ¦‚ç‡ï¼š40-60%

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **ä¸ä¿®æ”¹åŸä»“åº“ä»£ç **ï¼šæ‰€æœ‰æ–°ä»£ç éƒ½åœ¨ `dynaspec/` ç›®å½•ä¸‹
2. **æ•°æ®æ ¼å¼å…¼å®¹**ï¼šä½¿ç”¨ä¸ Gumiho ç›¸åŒçš„æ•°æ®æ ¼å¼
3. **å†…å­˜éœ€æ±‚**ï¼šè®­ç»ƒæ—¶éœ€è¦åŠ è½½å®Œæ•´çš„åŸºç¡€ LLM + è‰ç¨¿æ¨¡å‹
4. **è®­ç»ƒæŠ€å·§**ï¼š
   - å…ˆç”¨è¾ƒå°çš„ `cost_lambda` è®­ç»ƒå‡ ä¸ª epoch
   - é€æ­¥å¢å¤§ `cost_lambda` ä»¥æé«˜æ•ˆç‡
   - ç›‘æ§é—¨æ§ç»Ÿè®¡ï¼Œç¡®ä¿å—é€‰æ‹©çš„å¤šæ ·æ€§

## ğŸš€ DeepSpeed è®­ç»ƒä¼˜åŠ¿

ä½¿ç”¨ DeepSpeed è¿›è¡Œè®­ç»ƒå…·æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š

1. **å†…å­˜ä¼˜åŒ–**ï¼šZeRO Stage 3 å¤§å¹…é™ä½æ˜¾å­˜å ç”¨
2. **å¤š GPU åŠ é€Ÿ**ï¼šé«˜æ•ˆçš„åˆ†å¸ƒå¼è®­ç»ƒ
3. **æ··åˆç²¾åº¦**ï¼šFP16 è®­ç»ƒåŠ é€Ÿè®¡ç®—
4. **æ¢¯åº¦ç´¯ç§¯**ï¼šæ”¯æŒæ›´å¤§çš„æœ‰æ•ˆæ‰¹é‡å¤§å°
5. **è‡ªåŠ¨ä¼˜åŒ–**ï¼šè‡ªåŠ¨è°ƒåº¦å™¨å’Œä¼˜åŒ–å™¨é…ç½®

### DeepSpeed é…ç½®è¯´æ˜

`ds_config_hybrid.json` å…³é”®å‚æ•°ï¼š

- **ZeRO Stage 3**: æ¨¡å‹å‚æ•°ã€æ¢¯åº¦å’Œä¼˜åŒ–å™¨çŠ¶æ€çš„åˆ†ç‰‡
- **FP16**: æ··åˆç²¾åº¦è®­ç»ƒ
- **Gradient Clipping**: 0.5ï¼ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰
- **Batch Size**: 4 per GPU
- **å­¦ä¹ ç‡è°ƒåº¦**: WarmupDecayLR (warmup 6000 steps)

## ğŸ“š å‚è€ƒ

æœ¬å®ç°åŸºäºä»¥ä¸‹æ¦‚å¿µï¼š

1. **Speculative Decoding**: ä½¿ç”¨è‰ç¨¿æ¨¡å‹åŠ é€Ÿ LLM æ¨ç†
2. **Gumbel-Softmax**: å¯å¾®çš„ç¦»æ•£é€‰æ‹©
3. **æ··åˆä¸“å®¶ (MoE)**: åŠ¨æ€é€‰æ‹©ä¸åŒè®¡ç®—è·¯å¾„
4. **æˆæœ¬æ„ŸçŸ¥å­¦ä¹ **: åœ¨å‡†ç¡®ç‡å’Œæ•ˆç‡é—´æƒè¡¡
5. **DeepSpeed**: é«˜æ•ˆçš„å¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶

## ğŸ¤ è´¡çŒ®

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æäº¤ Issue æˆ– Pull Requestã€‚

## ğŸ“„ è®¸å¯è¯

éµå¾ª Gumiho åŸä»“åº“çš„è®¸å¯è¯ã€‚
